{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "03_GraphRec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stellaryoung/data_match/blob/master/03_GraphRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXslCTz8dai4"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuORkFPakhCc"
      },
      "source": [
        "### Attention.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2skXLM1dkkTM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, embedding_dims):\n",
        "        super(Attention, self).__init__()\n",
        "        self.embed_dim = embedding_dims\n",
        "        self.bilinear = nn.Bilinear(self.embed_dim, self.embed_dim, 1)\n",
        "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(0)\n",
        "\n",
        "    def forward(self, node1, u_rep, num_neighs):\n",
        "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
        "        x = torch.cat((node1, uv_reps), 1)\n",
        "        x = F.relu(self.att1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.att2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.att3(x)\n",
        "        att = F.softmax(x, dim=0)\n",
        "        return att"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GLZ0lZIkvRb"
      },
      "source": [
        "### Social_Aggregator.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "723n3fKok1nU"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import random\n",
        "from Attention import Attention\n",
        "class Social_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    Social Aggregator: for aggregating embeddings of social neighbors.\n",
        "    \"\"\"\n",
        "    def __init__(self, features, u2e, embed_dim, cuda=\"cpu\"):\n",
        "        super(Social_Aggregator, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.device = cuda\n",
        "        self.u2e = u2e\n",
        "        self.embed_dim = embed_dim\n",
        "        self.att = Attention(self.embed_dim)\n",
        "    def forward(self, nodes, to_neighs):\n",
        "        embed_matrix = torch.empty(len(nodes), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        for i in range(len(nodes)):\n",
        "            tmp_adj = to_neighs[i]\n",
        "            num_neighs = len(tmp_adj)\n",
        "            # \n",
        "            e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding \n",
        "            #slow: item-space user latent factor (item aggregation)\n",
        "            #feature_neigbhors = self.features(torch.LongTensor(list(tmp_adj)).to(self.device))\n",
        "            #e_u = torch.t(feature_neigbhors)\n",
        "\n",
        "            u_rep = self.u2e.weight[nodes[i]]\n",
        "\n",
        "            att_w = self.att(e_u, u_rep, num_neighs)\n",
        "            att_history = torch.mm(e_u.t(), att_w).t()\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "        return to_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e28p56rxk9Ku"
      },
      "source": [
        "### Social_encoder.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA-Jbm8glDcE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "# 注意：这里聚合的embedding是从用户-物品图中学习到user embedding!!!!!\n",
        "# \n",
        "class Social_Encoder(nn.Module):\n",
        "    def __init__(self, features, embed_dim, social_adj_lists, aggregator, base_model=None, cuda=\"cpu\"):\n",
        "        super(Social_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.social_adj_lists = social_adj_lists\n",
        "        self.aggregator = aggregator\n",
        "        if base_model != None:\n",
        "            self.base_model = base_model\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "        to_neighs = []\n",
        "        for node in nodes:\n",
        "            to_neighs.append(self.social_adj_lists[int(node)])\n",
        "        neigh_feats = self.aggregator.forward(nodes, to_neighs)  # user-user network\n",
        "        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)\n",
        "        self_feats = self_feats.t()   \n",
        "        # self-connection could be considered.\n",
        "        # 将社会关系图中用户的原始embedding(即item space的user embedding)\n",
        "        # 与聚合的邻居的embedding拼接在一起输入MLP网络得到\n",
        "        # 最终的user表示\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "        return combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqT3OCSk5sW5"
      },
      "source": [
        "agg_u_social = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, cuda=device)\n",
        "enc_u = Social_Encoder(lambda nodes: enc_u_history(nodes).t(), embed_dim, social_adj_lists, agg_u_social,\n",
        "                        base_model=enc_u_history, cuda=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHga1Na5l1vW"
      },
      "source": [
        "### UV_Aggregator.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwvBJ2jltpj"
      },
      "source": [
        "# 该模型最终返回的是用户与物品的embedding矩阵\n",
        "class UV_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    item and user aggregator: for aggregating embeddings of neighbors (item/user aggreagator).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, v2e, r2e, u2e, embed_dim, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Aggregator, self).__init__()\n",
        "        self.uv = uv\n",
        "        self.v2e = v2e\n",
        "        self.r2e = r2e\n",
        "        self.u2e = u2e\n",
        "        self.device = cuda\n",
        "        self.embed_dim = embed_dim\n",
        "        self.w_r1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_r2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, history_uv, history_r):\n",
        "\n",
        "        embed_matrix = torch.empty(len(history_uv), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        # 得到嵌入矩阵\n",
        "        for i in range(len(history_uv)):\n",
        "            history = history_uv[i]\n",
        "            num_histroy_item = len(history)\n",
        "            tmp_label = history_r[i]\n",
        "\n",
        "            if self.uv == True:\n",
        "                # user component\n",
        "                e_uv = self.v2e.weight[history]\n",
        "                uv_rep = self.u2e.weight[nodes[i]]\n",
        "            else:\n",
        "                # item component\n",
        "                e_uv = self.u2e.weight[history]\n",
        "                uv_rep = self.v2e.weight[nodes[i]]\n",
        "\n",
        "            e_r = self.r2e.weight[tmp_label]\n",
        "            x = torch.cat((e_uv, e_r), 1)\n",
        "            x = F.relu(self.w_r1(x))\n",
        "            o_history = F.relu(self.w_r2(x))\n",
        "            # 注意力机制\n",
        "            att_w = self.att(o_history, uv_rep, num_histroy_item)\n",
        "            att_history = torch.mm(o_history.t(), att_w)\n",
        "            att_history = att_history.t()\n",
        "\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "        return to_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oG05GdBl--O"
      },
      "source": [
        " ### UV_Encoder.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wnHyM7HmMOq"
      },
      "source": [
        "# 用户物品图上的主网络模块，UV_Aggreator作为子网络模块，在该网络模块中被调用。\n",
        "# 输出：用户/物品在聚合邻居后的表示信息\n",
        "class UV_Encoder(nn.Module):\n",
        "    # features:用户或者物品的embedding\n",
        "    # embed_dim:嵌入的维度\n",
        "    # history_uv_list:目标用户的历史购买物品或者目标物品的历史购买用户\n",
        "    # history_r_lists:对应的评分记录\n",
        "    # aggregator:聚合网络\n",
        "\n",
        "    def __init__(self, features, embed_dim, history_uv_lists, history_r_lists, aggregator, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.uv = uv\n",
        "        self.history_uv_lists = history_uv_lists\n",
        "        self.history_r_lists = history_r_lists\n",
        "        self.aggregator = aggregator\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "        tmp_history_uv = []\n",
        "        tmp_history_r = []\n",
        "        for node in nodes:\n",
        "            tmp_history_uv.append(self.history_uv_lists[int(node)])\n",
        "            tmp_history_r.append(self.history_r_lists[int(node)])\n",
        "\n",
        "        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  # user-item network\n",
        "\n",
        "        self_feats = self.features.weight[nodes]\n",
        "        # self-connection could be considered.\n",
        "        # 这里将物品/用户的原始embedding与从邻居聚合来embedding拼接在一起\n",
        "        # 然后进行线性变换，最终变换为最原始的维度\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnhIqWKd4T4g"
      },
      "source": [
        "agg_u_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=True)\n",
        "enc_u_history = UV_Encoder(u2e, embed_dim, history_u_lists, history_ur_lists, agg_u_history, cuda=device, uv=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ1deBcmmbYt"
      },
      "source": [
        "### GraphRec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jNHmAQCmeLK"
      },
      "source": [
        "# enc_u:       用户建模的网络模块\n",
        "# enc_v_history：  物品建模的网络模块\n",
        "# 这里在实例化GraphRec类的时候，直接将2个网络模块的实例传输进去，减少总网络模块的参数，也是一种代码方式吧\n",
        "class GraphRec(nn.Module):\n",
        "    def __init__(self, enc_u, enc_v_history, r2e):\n",
        "        super(GraphRec, self).__init__()\n",
        "        self.enc_u = enc_u\n",
        "        self.enc_v_history = enc_v_history\n",
        "        self.embed_dim = enc_u.embed_dim\n",
        "        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
        "        self.w_uv3 = nn.Linear(16, 1)\n",
        "        self.r2e = r2e    # 这个代码没有用到\n",
        "        # 用到4个batch norm层\n",
        "        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn4 = nn.BatchNorm1d(16, momentum=0.5)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, nodes_u, nodes_v):\n",
        "        # 得到用户向量表示，物品的向量表示\n",
        "        embeds_u = self.enc_u(nodes_u)\n",
        "        embeds_v = self.enc_v_history(nodes_v)\n",
        "\n",
        "        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
        "        x_u = F.dropout(x_u, training=self.training)\n",
        "        x_u = self.w_ur2(x_u)\n",
        "        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
        "        x_v = F.dropout(x_v, training=self.training)\n",
        "        x_v = self.w_vr2(x_v)\n",
        "\n",
        "        x_uv = torch.cat((x_u, x_v), 1)\n",
        "        x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.bn4(self.w_uv2(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        scores = self.w_uv3(x)\n",
        "        return scores.squeeze()\n",
        "\n",
        "    def loss(self, nodes_u, nodes_v, labels_list):\n",
        "        scores = self.forward(nodes_u, nodes_v)\n",
        "        return self.criterion(scores, labels_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWorBSo3d0O2"
      },
      "source": [
        "### 代码运行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGKvzFvDLqua"
      },
      "source": [
        "### 论文思路：\n",
        "**该模型的思路还是比较直观的，用2张图，分别是用户-物品图，以及用户-用户图，然后应用图网络aggregation的思想，进行特征表示。**\n",
        "* 本文分别对用户、物品、用户物品的评分进行embedding,这里对评分进行\n",
        "embedding可以**理解为对用户-物品图(用户评分矩阵)的边进行表示**。\n",
        "* 评分的embedding非常直接，如果有[1,2,3,4,5],那么则对应5个d维的embedding向量。 \n",
        "***\n",
        "第一部分：表示用户信息，分别是物品聚合以及用户聚合得到的向量进行拼接\n",
        "* step1:物品聚合：从用户购买过的**历史物品**的图信息进行聚合，需要用到\n",
        "item和score的embedding\n",
        "* step2:社会关系聚合：从社交关系图上进行聚合，聚合**用户的邻居**，需要用到从**用户物品图上**得到的user embedding\n",
        "***\n",
        "第二部分：表示物品信息，使用用户聚合 \n",
        "* 用户聚合：从**买过该物品的历史用户**进行聚合，需要用到user embedding和score embedding。\n",
        "***\n",
        "注意：\n",
        "* **用户聚合与物品聚合从模型的操作来讲，本质是一样的，只是用户聚合用的是item embedding,物品聚合使用的是user embedding，因此代码中UV_Aggregator、UV_Encoder可以都适用于用户与物品。**\n",
        "* 所有聚合的方法是使用**注意力机制**\n",
        "***\n",
        "第三部分：将表示拼接作为网络输入进行训练\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Ct2Yb0xXDU"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, best_rmse, best_mae):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        batch_nodes_u, batch_nodes_v, labels_list = data\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print('[%d, %5d] loss: %.3f, The best rmse/mae: %.6f / %.6f' % (\n",
        "                epoch, i, running_loss / 100, best_rmse, best_mae))\n",
        "            running_loss = 0.0\n",
        "    return 0\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    tmp_pred = []\n",
        "    target = []\n",
        "    with torch.no_grad():\n",
        "        for test_u, test_v, tmp_target in test_loader:\n",
        "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
        "            val_output = model.forward(test_u, test_v)\n",
        "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
        "            target.append(list(tmp_target.data.cpu().numpy()))\n",
        "    tmp_pred = np.array(sum(tmp_pred, []))\n",
        "    target = np.array(sum(target, []))\n",
        "    expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
        "    mae = mean_absolute_error(tmp_pred, target)\n",
        "    return expected_rmse, mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsUcd2S0_Rv6"
      },
      "source": [
        "### 模型的训练与测试\n",
        "* 训练过程中需要融入edge embedding训练网络参数，得到用户与物品的最终表示\n",
        "* 推断过程直接使用最终得到的用户与物品表示进行推断。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjUbW-Bzd4gP"
      },
      "source": [
        "path_data = '/content/drive/My Drive/recommend_system/graph_rec_data/toy_dataset.pickle'\n",
        "data_file = open(path_data, 'rb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_JCD8q-eKQ_"
      },
      "source": [
        "# 字典、列表、字典、字典\n",
        "# history_u_lists：用户购买历史记录（用户-物品列表的字典)\n",
        "# history_ur_lists：用户的评分\n",
        "# history_v_lists\n",
        "# history_vr_lists\n",
        "# rain_u,train_v,train_r:training_set (user, item, rating)，用户，物品，评分\n",
        "# test_u,test_v,test_r:testing set (user, item, rating)，用户，物品，评分\n",
        "# social_adj_lists：用户间的邻接矩阵\n",
        "# ratings_list：评分列表字典，key:value ----- 评分(0.5-4.0)：值（0-7），8个维度\n",
        "history_u_lists,history_ur_lists,history_v_lists,history_vr_lists,\\   \n",
        "train_u,train_v,train_r,\\\n",
        "test_u,test_v,test_r,\\\n",
        "social_adj_lists,ratings_list=pickle.load(data_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0q_fS77evmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4212b42a-a993-47d9-e596-16124f79759d"
      },
      "source": [
        "print(type(history_u_lists)) # 带有默认值的字典\n",
        "print(type(train_u))\n",
        "print(type(social_adj_lists))\n",
        "print(type(ratings_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'collections.defaultdict'>\n",
            "<class 'list'>\n",
            "<class 'collections.defaultdict'>\n",
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APC6ocUQtE5w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e221c14-0ecc-479a-f23a-844af0e47818"
      },
      "source": [
        "batch_size = 128\n",
        "test_batch_size = 1000\n",
        "trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),torch.FloatTensor(train_r))\n",
        "testset = torch.utils.data.TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v),torch.FloatTensor(test_r))\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=True)\n",
        "num_users = history_u_lists.__len__()\n",
        "num_items = history_v_lists.__len__()\n",
        "num_ratings = ratings_list.__len__()\n",
        "print(num_users,num_items,num_ratings) # 用户数：705 物品数：1941  评分维度：8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "705 1941 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTP3iij-u03s"
      },
      "source": [
        "# step1:对用户、物品、评分分别进行嵌入表示\n",
        "u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
        "v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
        "r2e = nn.Embedding(num_ratings, embed_dim).to(device)\n",
        "\n",
        "# user feature(用户特征)\n",
        "# features: item * rating\n",
        "agg_u_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=True)\n",
        "enc_u_history = UV_Encoder(u2e, embed_dim, history_u_lists, history_ur_lists, agg_u_history, cuda=device, uv=True)\n",
        "\n",
        "# neighobrs\n",
        "agg_u_social = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, cuda=device)\n",
        "enc_u = Social_Encoder(lambda nodes: enc_u_history(nodes).t(), embed_dim, social_adj_lists, agg_u_social,\n",
        "                        base_model=enc_u_history, cuda=device)\n",
        "\n",
        "# item feature: user * rating (物品特征)\n",
        "agg_v_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=False)\n",
        "enc_v_history = UV_Encoder(v2e, embed_dim, history_v_lists, history_vr_lists, agg_v_history, cuda=device, uv=False)\n",
        "\n",
        "# model\n",
        "# enc_u:社会关系图中的user latent factor\n",
        "# enc_v_history:用户物品图中的user latent factor和item latent factor\n",
        "graphrec = GraphRec(enc_u, enc_v_history, r2e).to(device)\n",
        "optimizer = torch.optim.RMSprop(graphrec.parameters(), lr=args.lr, alpha=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf0O0Vy_x0LF"
      },
      "source": [
        "best_rmse = 9999.0\n",
        "best_mae = 9999.0\n",
        "endure_count = 0\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "\n",
        "    train(graphrec, device, train_loader, optimizer, epoch, best_rmse, best_mae)\n",
        "    expected_rmse, mae = test(graphrec, device, test_loader)\n",
        "    # please add the validation set to tune the hyper-parameters based on your datasets.\n",
        "\n",
        "    # early stopping (no validation set in toy dataset)\n",
        "    if best_rmse > expected_rmse:\n",
        "        best_rmse = expected_rmse\n",
        "        best_mae = mae\n",
        "        endure_count = 0\n",
        "    else:\n",
        "        endure_count += 1\n",
        "    print(\"rmse: %.4f, mae:%.4f \" % (expected_rmse, mae))\n",
        "\n",
        "    if endure_count > 5:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHp3mv8CELs3"
      },
      "source": [
        "### 问题的思考\n",
        "模型在训练阶段要输入评分记录，在测试阶段没有评分记录,模型如何进行推断？\n",
        "\n",
        "答：\n",
        "* 模型训练实际上就是训练一套网络参数，训练时用到用户物品历史评分记录、社交关系记录得到最终的用户表示与物品表示\n",
        "* 测试时只需要用到最终的用户表示与物品表示进行推断，本论文在代码实现上在测试集上并没有将训练好的用户表示与物品表示直接提取出来。而是利用网络模块重新计算一遍。**实际效果与提取出来应该是一致的**\n",
        "* 如果有大量新的用户与物品加入，这种用户与物品的表示需要重新计算。\n",
        "\n",
        "模型与数据的分离？\n",
        "* 这篇论文的代码实现，模型与代码结合过于紧密，没法在只有测试集与模型训练好的参数下得到测试集评分，网络模块的重新定义一定要用到训练集\n",
        "* 以后在实现时，不仅保存模型参数，还可以保存模型输出的最终物品与用户表示，当有最终的用户与物品表示时，就可以在测试时不用在forward一遍了。实际上测试集往往小于训练集，采用论文中的做法，在测试集推断的计算量更加小。\n",
        "* 基于上述原因，该论文的网络定义存在一种别扭感（主要时edge的存在）\n",
        "* 该论文在训练时的评分信息，不仅在最终损失函数中被使用，还作为edge\n",
        "embedding嵌入到网络中。\n",
        "\n"
      ]
    }
  ]
}