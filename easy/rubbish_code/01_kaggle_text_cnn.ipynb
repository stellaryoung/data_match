{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73521,
     "status": "ok",
     "timestamp": 1583127231774,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "75FtDh3hundx",
    "outputId": "a415bb15-edb6-4686-ddd8-04c625564ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/01 text_classification/01 kaggle_google_textclassification/data/my.zip\n",
      "  inflating: /content/drive/My Drive/01 text_classification/glove.twitter.27B.25d.txt  \n",
      "  inflating: /content/drive/My Drive/01 text_classification/glove.twitter.27B.50d.txt  \n",
      "  inflating: /content/drive/My Drive/01 text_classification/glove.twitter.27B.100d.txt  \n",
      "  inflating: /content/drive/My Drive/01 text_classification/glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip  /content/drive/'My Drive'/'01 text_classification'/'01 kaggle_google_textclassification'/data/my.zip -d /content/drive/'My Drive'/'01 text_classification'/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6962,
     "status": "ok",
     "timestamp": 1583386310057,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "GZv7kVl8d08M",
    "outputId": "811d487c-d1cc-4a70-8118-88e2293694f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
      "\r",
      "\u001b[K     |█▊                              | 10kB 23.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 20kB 31.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 30kB 38.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 40kB 44.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 51kB 38.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 61kB 41.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 71kB 34.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 81kB 35.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 92kB 37.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 102kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 112kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 122kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 133kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 143kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 153kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 163kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 174kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 184kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 194kB 35.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 204kB 35.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.2.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4602,
     "status": "ok",
     "timestamp": 1583386181635,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "sLLBE7m4KMd9",
    "outputId": "9b90bc23-4bb5-4b53-e5f9-1fb771fa4d21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(torch.cuda.is_available())   # 需要设置笔记本从而打开GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIb9CV3h5GdU"
   },
   "source": [
    "### 模型定义(TextCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXSahq4V5c8P"
   },
   "source": [
    "#### 定义需要的layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPi-S9HJ74ha"
   },
   "source": [
    "**线性层定义与封装**\n",
    "$y=x A^{T}+b$\n",
    "\n",
    "其中$A$是参数矩阵(weight parameters),$b$是bias parameters\n",
    "\n",
    "pytorch提供了这个类torch.nn.Linear,该类有2个成员变量weight和bias\n",
    "\n",
    "总结：\n",
    "\n",
    "**基本网络模块的必要步骤：**\n",
    "* 初始化，主要是所依托的其他模块的定义，同时调用参数初始化函数\n",
    "* 参数初始化成员函数定义\n",
    "* 前向传播过程定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YKbwCyBr5OBr"
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "  def __init__(self,in_dim,out_dim):  # 成员函数self不要忘\n",
    "    super(Linear,self).__init__()\n",
    "    self.linear = torch.nn.Linear(in_dim, out_dim, bias=True)\n",
    "    self.init_params()  # 调用成员函数初始化参数\n",
    "  def init_params(self): # 就是给weight与bias进行初始化\n",
    "    # 使用何恺明正态分布初始化权重，参数初始化要具体问题，具体分析\n",
    "    nn.init.kaiming_normal_(self.linear.weight)\n",
    "    nn.init.constant_(self.linear.bias, 0)\n",
    "  def forward(self,x):\n",
    "    y = self.linear(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVeL4NmwDuS-"
   },
   "source": [
    "#### 封装一维卷积层（用于文本）\n",
    "参数数量：\n",
    "* weights: out_channels,in_channels,kernel_size\n",
    "* bias: out_channels\n",
    "* * *\n",
    "* convolution operation:\n",
    "filter: $\\mathbf{w} \\in \\mathbb{R}^{h k}$\n",
    "该卷积核应用于h个words去产生新的feature。\n",
    "\n",
    "* * *\n",
    "* **特征计算的数学表示：**\n",
    "$c_{i}=f\\left(\\mathbf{w} \\cdot \\mathbf{x}_{i: i+h-1}+b\\right)$\n",
    "这里的句子的窗口大小时h,乘以卷积核，然后再加上偏置b,最后通过f进行激活,f是一个non-linear function比如说hyperbolic tangent(tanh)。\n",
    "* 从参数的角度考虑，这里默认输出通道为1\n",
    "* * *\n",
    "\n",
    "* **窗口进行滑动**\n",
    "取遍所有窗口，将k维词向量所有的窗口$\\left\\{\\mathbf{x}_{1: h}, \\mathbf{x}_{2: h+1}, \\dots, \\mathbf{x}_{n-h+1: n}\\right\\}$进行卷积操作得到$\\mathbf{c}=\\left[c_{1}, c_{2}, \\ldots, c_{n-h+1}\\right]$，这里成为feature map。\n",
    "$\\mathbf{c} \\in \\mathbb{R}^{n-h+1}$： 卷积后的特征维度\n",
    "\n",
    "* * *\n",
    "\n",
    "* 进行max-over-time pooling operation操作，得到最大值$\\hat{c}=\\max \\{\\mathbf{c}\\}$\n",
    "**背后的思想：捕获feature map中最重要的特征，这种策略自然解决了句子的长度变化问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-KphOKokDolP"
   },
   "outputs": [],
   "source": [
    "# 注意：使用官方提供的网络模块一定要弄清其进行了哪些操作\n",
    "# 官方一维卷积模块并没有提供激活操作，因此最后得到的特征还需要激活一下\n",
    "class Conv1d(nn.Module):\n",
    "  def __init__(self,in_channels,out_channels,kernel_size_list):\n",
    "    super(Conv1d,self).__init__()\n",
    "    self.convs = torch.nn.ModuleList()\n",
    "    for size in kernel_size_list: # 定义卷积核大小不同的卷积模块\n",
    "      self.convs.append(nn.Conv1d(in_channels,out_channels,size))\n",
    "    self.init_params\n",
    "\n",
    "  def init_params(self):\n",
    "    for m in self.convs:\n",
    "      nn.init.xavier_uniform_(m.weight)\n",
    "      nn.init.constant_(m.bias,0.1)\n",
    "  def forward(self,x):   # 返回一个列表，列表中是len(kernel_size_list)个张量\n",
    "    # 每个卷积网络都得到一个特征表示，放入到列表中\n",
    "    return [F.relu(conv(x)) for conv in self.convs]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1202,
     "status": "ok",
     "timestamp": 1583317422202,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "gZemfskJLljj",
    "outputId": "14e0adbb-9c5b-4eef-c50c-7c973c79be71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([20, 1, 9])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([20, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "# 测试定义的卷积模块\n",
    "# input:(batch_num,in_channels,length)\n",
    "# output:(batch_num,out_channels,计算出的维度)\n",
    "myConv = Conv1d(100,1,[2,5])\n",
    "input = torch.randn(20,100,10)  # batch_num,in_channels,length\n",
    "output = myConv(input)\n",
    "print(len(output))\n",
    "print(type(output))\n",
    "for i in range(2):\n",
    "  print(type(output[i]))\n",
    "  print(output[i].shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1480,
     "status": "ok",
     "timestamp": 1583309448222,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "tozcOTpUb__3",
    "outputId": "7098e37d-55ef-49bd-841c-482b1ec97ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([1, 2, 3])\n",
      "tensor([[[ 100.],\n",
      "         [1000.]]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[ 100., 1000.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.functional.max_pool1d(*args, **kwargs) # *var: non-keyword variable, **var: keyworded variable\n",
    "# torch.cat() can be seen as an inverse operation for torch.split() and torch.chunk()\n",
    "test_tensor = torch.tensor([[4., -5., 100], [1., -1., 1000]])\n",
    "print(test_tensor.shape)\n",
    "test_tensor.unsqueeze_(dim=0)\n",
    "print(test_tensor.shape)\n",
    "output = F.max_pool1d(test_tensor,test_tensor.shape[2]) # 输入的test_tensor必须是3维的，考虑batch_num\n",
    "# 函数的第一个参数是池化的数据，第2个参数是kernel_size即池化核的大小\n",
    "print(output)\n",
    "print(output.squeeze_(dim=2).shape) # 在第2个维度最大池化，然后在第2个维度squeeze\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1583310846578,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "drDcrYXimuhu",
    "outputId": "a5a4b2bb-d8be-4f7f-94ea-0c74f04cd342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   4.,   -5.,  100.],\n",
      "        [   1.,   -1., 1000.],\n",
      "        [   1.,    2.,    3.],\n",
      "        [   4.,    5.,    6.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# concatenate\n",
    "test_tensor1 = torch.tensor([[4., -5., 100], [1., -1., 1000]])\n",
    "test_tensor2 = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "test_list = [test_tensor1,test_tensor2]\n",
    "res1 = torch.cat(test_list,dim=0)  # dim指定拼接的维度，也是拼接操作后张量改变的维度\n",
    "print(res1)\n",
    "print(res1.shape)  # 0维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ni5Sl5csb1ez"
   },
   "source": [
    "### 定义最终的TextCNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWfhj_iYUH_p"
   },
   "source": [
    "**通道数的个人理解**\n",
    "\n",
    "--可以理解为特征的维度，比如对文本进行卷积，初始输入通道数就是embedding_dim,输出通道数则可以用户指定，输出通道数越大代表保存的抽取的特征越丰富。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uIdM_7byb70H"
   },
   "outputs": [],
   "source": [
    "# This TextCNN model only one layer CNN to extract features.\n",
    "# 为什么加载预先训练好的词向量能够提升模型效果？？？\n",
    "class TextCNN(nn.Module):\n",
    "  def __init__(self,embedding_dim,out_channels,kernel_size_list,\n",
    "               output_dim,dropout,pretrained_embeddings):\n",
    "    super(TextCNN,self).__init__()\n",
    "    self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings,freeze=False)\n",
    "    # freeze=False parameters get updated during learning process\n",
    "    self.conv = Conv1d(embedding_dim,out_channels,kernel_size_list) # extract text features\n",
    "    input_dim = len(kernel_size_list)*out_channels  # input dim of linear layer\n",
    "    self.linear = Linear(in_dim=input_dim,out_dim=output_dim)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  def forward(self,x):\n",
    "    # text:(sent_len,batch_size)  # why????\n",
    "    text,_ = x  \n",
    "    text = text.permute(1,0) # text:(batch_size,sent_len)\n",
    "    embeded = self.embedding(text) # (batch_size,sent_len,embedding_dim)\n",
    "    embeded = embeded.permute(0,2,1) \n",
    "    conv1ded = self.conv(embeded)  # 得到的张量列表\n",
    "    pooled = [F.max_pool1d(conv,conv.shape[2]).squeeze(dim=2) for conv in conv1ded]\n",
    "    # 在第2个维度上进行1d pool，最后去除该维度\n",
    "    # 对每个卷积核卷出的特征进行最大池化操作\n",
    "    final = torch.cat(pooled,dim=1) # pooled是个列表，将特征拼接在一起\n",
    "    # final:[batch_size,out_channels*len(kernel_size_list)]\n",
    "    droped = self.dropout(final)\n",
    "    z = self.linear(droped)  # 这里只进行线性变化，没有激活？？？？？？？\n",
    "    return z          # [batch_size,output_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vVBr_qbm1ZC0"
   },
   "outputs": [],
   "source": [
    "def info(var):\n",
    "  print(\"shape:{}\".format(var.shape))\n",
    "  print(\"type:{}\".format(type(var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2rPrFKQMGG6"
   },
   "source": [
    "### Test TextCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1583376272083,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "RJlHzYutu7B-",
    "outputId": "1a76c3b2-c0c3-434a-b30d-f9aeb3406fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:torch.Size([2, 1])\n",
      "type:<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)   # 限定随机数\n",
    "# 模拟tokenization后的文本，注意这里面的张量是整型数字\n",
    "text = torch.LongTensor([[1,2,4,5],[4,3,2,9]]) \n",
    "text = text.permute(1,0) # (batch_size,sen_len)=(2,5)\n",
    "label = torch.LongTensor([1,0])\n",
    "x = (text,label)\n",
    "# 模拟预训练好的词向量参数，参数维度[num,embedding_dim],此处num >= 10\n",
    "# 文本中标号最大为9,词向量个数为10，嵌入维度为3\n",
    "pretrained_embedding = torch.FloatTensor([[1, 2.3, 3], \n",
    "                      [2, 5.1, 6.3],\n",
    "                      [3, 5.1, 6.3],\n",
    "                      [4, 5.1, 6.3],\n",
    "                      [5, 5.1, 6.3],\n",
    "                      [6, 5.1, 6.3],\n",
    "                      [7, 5.1, 6.3],\n",
    "                      [8, 5.1, 6.3],\n",
    "                      [9, 5.1, 6.3],\n",
    "                      [10, 5.1, 6.3],\n",
    "                      ])\n",
    "# info(pretrained_embedding)\n",
    "# print(x)\n",
    "textcnn = TextCNN(embedding_dim=3,out_channels=2,kernel_size_list=[2,3],\n",
    "                  output_dim = 1,dropout=0.5,\n",
    "                  pretrained_embeddings=pretrained_embedding)\n",
    "output=textcnn(x)\n",
    "info(output)\n",
    "# for param in textcnn.parameters():\n",
    "#   print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1708,
     "status": "ok",
     "timestamp": 1583386205819,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "pURO8kf714aE",
    "outputId": "1bd7dc59-7980-483f-821c-de000ad26a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda, # cuda is:  1\n",
      "cuda:0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"device is cuda, # cuda is: \", n_gpu)\n",
    "    else:\n",
    "        print(\"device is cpu, not recommend\")\n",
    "    return device, n_gpu\n",
    "device, n_gpu = get_device()\n",
    "print(device)\n",
    "print(n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4513,
     "status": "ok",
     "timestamp": 1583386213898,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "etixKLK9ShOo",
    "outputId": "d8c7ca76-e5d6-484b-97d5-9aff345186e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('/content/drive/My Drive/01 text_classification/01 kaggle_google_textclassification/data/train.csv') \n",
    "print(train_data.shape)   # 训练数据只有7613条\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUVg9uZJEhP3"
   },
   "source": [
    "### 参考资料\n",
    "[01 TorchText用法示例及完整代码](https://blog.csdn.net/nlpuser/article/details/88067167)\n",
    "\n",
    "[02 A Comprehensive Introduction to Torchtext (Practical Torchtext part 1)](\n",
    "http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/)\n",
    "\n",
    "[03 Language modeling tutorial in torchtext (Practical Torchtext part 2)](http://mlexplained.com/2018/02/15/language-modeling-tutorial-in-torchtext-practical-torchtext-part-2/)\n",
    "\n",
    "[04 官方文档](https://pytorch.org/text/)\n",
    "\n",
    "[05 torchtext读取json文件（引起重视）](https://blog.csdn.net/weixin_43896398/article/details/85559172)\n",
    "\n",
    "[06 json格式专tsv与csv格式 ](https://blog.csdn.net/qq_41868948/article/details/81008520)\n",
    "### 使用tortext构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RUurpICYTA7M"
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ABTpDOyMmhX"
   },
   "source": [
    "**torchtext.vocab:**Defines a vocabulary object that will be used to numericalize a field\n",
    "\n",
    "**torchtext.data.Field:**Defines a datatype together with instructions for converting to Tensor.(定义数据类型以及转换为张量的指令)\n",
    "* It holds a Vocab object that defines the set of possible values for elements of the field and their corresponding numerical representations（Field中包含一个Vocab对象，该对象定义了元素可能值的集合以及对应的数值表示）\n",
    "* 该对象同时包含tokenization method以及转换后tensor的数据类型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11411,
     "status": "ok",
     "timestamp": 1583386233513,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "g9I60aCWWg5r",
    "outputId": "e3fcd47d-98b0-481c-e743-378fd4f0c315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train: 6852, dev:761, test:3263\n"
     ]
    }
   ],
   "source": [
    "fix_length = 100\n",
    "# 训练数据的路径\n",
    "root_dir = '/content/drive/My Drive/01 text_classification/01 kaggle_google_textclassification/data/'\n",
    "path1 = root_dir+'train.csv'\n",
    "path2 = root_dir+'test.csv'\n",
    "# 分别对应文本以及标签\n",
    "TEXT = data.Field(tokenize='spacy', lower=True, include_lengths=True, fix_length=None) \n",
    "# 调试1：不限定句子的长度 \n",
    "LABEL = data.LabelField(dtype=torch.long)\n",
    "fields = [(\"id\",None),(\"keyword\",None),(\"location\",None),(\"text\",TEXT),(\"target\",LABEL)]\n",
    "raw_dataset = data.TabularDataset(path=path1, format=\"csv\", fields=fields, skip_header=True)\n",
    "train_dataset,dev_dataset = raw_dataset.split(split_ratio=[0.9,0.1])   # 划分为训练数据集以及验证集\n",
    "fields = [(\"id\",None),(\"keyword\",None),(\"location\",None),(\"text\",TEXT)]\n",
    "test_dataset = data.TabularDataset(path=path2, format=\"csv\", fields=fields, skip_header=True)\n",
    "print(\"the size of train: {}, dev:{}, test:{}\".format(len(train_dataset.examples), len(dev_dataset.examples),len(test_dataset.examples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0DQB1WUz0YA"
   },
   "source": [
    "### 使用建立好数据集建设vocab,用于将文本转换成数字序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TLkAwBY90_jb"
   },
   "outputs": [],
   "source": [
    "embedding_file = '/content/drive/My Drive/01 text_classification/glove.twitter.27B.200d.txt'\n",
    "cache_dir = '/content/drive/My Drive/01 text_classification/cache'\n",
    "vectors = Vectors(embedding_file, cache_dir)  # 初始化词向量\n",
    "# 对文本建立词汇表，会遍历所有dataset的example将TEXT相关的内容进行登记，建立单词到数字的映射以及数字到单词的映射\n",
    "TEXT.build_vocab(train_dataset,dev_dataset,test_dataset,vectors=vectors,unk_init=torch.Tensor.normal_)\n",
    "# 可选参数max_size:dictate how many words are in the vocabulary,限定词汇表大小\n",
    "# 可选参数min_freq：确保词汇表中出现单词的词频\n",
    "# 对标签建立词汇表，感觉这一步可能没有必要\n",
    "LABEL.build_vocab(train_dataset,dev_dataset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoxGQGDh4LSK"
   },
   "source": [
    "### Creating an Iterator to pass the data to our model(建立一个迭代器用于模型训练，batch的划分就在这步)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sqa8KQJTc-by"
   },
   "outputs": [],
   "source": [
    "# 随机种子\n",
    "seed = 3456\n",
    "# 句子长度，这里没有用到\n",
    "# sequence_length= 100\n",
    "# 输出模型的保存地址\n",
    "model_file='/content/sample_data/model_saved/'+'model1.pt'\n",
    "# 日志文件根目录，用于保存画图数据\n",
    "log_dir='/content/sample_data/log'\n",
    "# Whether to run training.\n",
    "do_train = True\n",
    "# 多少步存储一次模型\n",
    "print_step=10\n",
    "# 优化参数\n",
    "dropout=0.4\n",
    "epoch_num=2\n",
    "batch_size = 64\n",
    "# 模型参数\n",
    "output_dim=2\n",
    "# TextCNN 参数\n",
    "out_channels = 200       \n",
    "kernel_size_list=[2,3]\n",
    "# word Embedding\n",
    "embedding_dim = 200 \n",
    "glove_word_size = 1.2e6   #预训练词汇量的单词数   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1583386280648,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "fNd6Xyp9Cajr",
    "outputId": "5d6d5ea8-7927-4e98-e660-249ec7b38362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda, # cuda is:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device, n_gpu = get_device()\n",
    "train_iter, dev_iter = data.BucketIterator.splits(\n",
    "        (train_dataset,dev_dataset), batch_sizes=(batch_size,batch_size), \n",
    "        sort_key=lambda x: len(x.text), \n",
    "        sort_within_batch=True, \n",
    "        repeat=False, shuffle=True, \n",
    "        device=device)\n",
    "test_iter = data.Iterator(test_dataset,batch_size=64,device=device,sort=False,sort_within_batch=False,repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1583380638691,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "5z3pISenlJNY",
    "outputId": "21bc62cb-14c8-45af-ce43-6dfb00d5861e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 14x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.target]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
      "2\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 13, 13, 13], device='cuda:0')\n",
      "tensor([[  144,    23,    20,   119,    14,   144,    60,     3,   174,   773,\n",
      "          4087,   104,   378,    11,   623,     4,     3,   217,     2,     3,\n",
      "           180,  8773,    87,   444, 11817,   128,   118,  6583, 10224,     3,\n",
      "          9586,   933,   135,   270,  4229,  9925,    53,   233,   180,     3,\n",
      "           654,   107,     3,     7,    81, 28619,    46,  1267,   144,   144,\n",
      "           933,   632, 11475,   144,    53,   319, 11969, 10727,  6602, 14288,\n",
      "           386,   153,  8609,   818],\n",
      "        [   30,   556,     3,    35,    21,    30,    61,   921,   124,   151,\n",
      "           261,   211,  2641,   202,   145,     2,  1590,  6260, 12567,   418,\n",
      "            30,  2114,   142,   992,   375,    32,  7679,    82,    49,   238,\n",
      "            33,  1494,   691,   116,  3706,    11,    18,   618,   758,  2902,\n",
      "           285,     3,   238,    56,    16,   355,  2304,   116,    30,    30,\n",
      "          1494,     8,   415,    30,    30,  1723,    46, 29031,    22,  3921,\n",
      "             9,    77,    89,     9],\n",
      "        [  566,   311,   562,   144,   311,   566,   906,   692,     3,   451,\n",
      "          1797,   379,   220,  2327,   557,   842,  4735,    16,   560,  1389,\n",
      "          1705,    89,    87,  6384, 25249,    20,     9,    14,   119,     9,\n",
      "             9,   107,    92,    11,    10,    46,    38,   125,   124,  2066,\n",
      "          1999,  1336,     9,     3,  5735,  8955,    54,     5,   566,   566,\n",
      "           107,  1125,   831,   566,   111,   654, 16292,     5,    14,   960,\n",
      "           222, 14228,  2541,   865],\n",
      "        [   65,    41,    10, 25991,    41,    65,   135,  2502,   670,     9,\n",
      "            44,   483,  4280,   348,   104,   591, 15090,  1455,   640,    10,\n",
      "             7,   276,   252,  2936,   894,    59,     3,  6129,    35,    69,\n",
      "           682,    49,     5,    38,  2256,   659,     6,   100,   107,  3046,\n",
      "            20,  2067,    69,  1562,  5584, 14347,     8,    40,    65,    65,\n",
      "            49,    42, 26917,    65,    46,   285,    54,    26,   192,   701,\n",
      "           671,    60,   178,   553],\n",
      "        [  731,    21, 25555,    11,     6,   731,   713,    37,   158,   930,\n",
      "            12,     8,  2775,    23,   211,     7, 15068,   694,    85,   140,\n",
      "           817,   825,     8,   100,     4,    12,   153,     9,   178,   242,\n",
      "           126,   138,    86,     6,    13,    73,    68,   162,     2,    45,\n",
      "           656,  1513,   242,    13,     3,  2603,  2277,    35,   731,   731,\n",
      "           138,   577,     8,   731,   568,  3191,     8,  1056,     9,    19,\n",
      "          1146,  6817,    10,   451],\n",
      "        [   44,    37,  1291,    66,   498,    44,    84,  8420,    64,  1001,\n",
      "          3384,   354,    71,  5449,    81,     3,    64,    72,   453,    12,\n",
      "            71,   277,   409,   219,  2701,    67,  2667,    74,     6,   590,\n",
      "            87,   356,     2,   205,  4019,   389,   366,    11,  7612,   584,\n",
      "           424,  7054,   590,  1053,  1021,   695,  1512,   719,    44,    44,\n",
      "           356,  1186,  1413,    44,    54,    44,   996,  7928,    11, 25738,\n",
      "          2696,     3,  2749,   232],\n",
      "        [   28,     8, 26888,    53,    14,    28,  1999,    88,    18,   803,\n",
      "           110,   542,  4230,  1100,   570,   821,    67,    49,    27,  1026,\n",
      "           371,   287,    13,   596,    15,    38,   894,    67,   428,    28,\n",
      "           210,     8,  1875,   158,   289,    15,    24,   248,     2,   725,\n",
      "          4746,  1150,    28,  1854,   268,   195,    10,    48,    28,    28,\n",
      "             8,   506,     7,    28,    10,    20,  6387,     5,   168,     2,\n",
      "           323,  1172,  2945,  6577],\n",
      "        [    6,     6,  3587,   995,  1056,     6,     8,     6,   704,   166,\n",
      "            58,   685,  4523,    22,   133,    13,  3060,    38,     6,   254,\n",
      "             4,   392,    20,  3922,    80,   116,    10,    32,   731,   221,\n",
      "             2,     3,     2,   126,   281,    29,    85,     5,  3764,  1211,\n",
      "             7,    53,   221,    10,    22,  4912,  3012,    44,     6,     6,\n",
      "             3,   292,  3553,     6,    55,   656, 28666,    26,    14, 14931,\n",
      "             3,   183,  2673,  2639],\n",
      "        [  524,   146, 26846,   791,   414,   524,  1608, 27928,     3,   438,\n",
      "           157,   401,   901,     8,     8,  1647,   565,  1455,   343,  2128,\n",
      "            25, 20455,   490,   504,    22,    19,  7274,  1620,   270,   123,\n",
      "         26511,   280, 25008,   333,  1318,     3,   326,     4,    37,    43,\n",
      "           891,   463,   123,     3,   291,     7,    64,  2096,   524,   524,\n",
      "           280,   318,    13,   524,   219,   424,    23,    72,    89,    19,\n",
      "           366,     8,    10,    12],\n",
      "        [    8,  1060,   525,    21,    15,     8,     4, 23012,   821,    25,\n",
      "           317,    26, 17689,   257,   609, 15861,   497,    16,   469,   103,\n",
      "            76,     2,    20,    29,   652,     6,   572,  2148,  3719,   207,\n",
      "             2,   736,     2,    46,  1858,  1842,  2499,     4,   583, 28754,\n",
      "           216,    28,   207,   136,  1782,     2,  3305,  2739,     8,     8,\n",
      "           736,    45,   598,     8,     5,    16,   325,     6,   276,   802,\n",
      "           610,  3083,  1490,  4103],\n",
      "        [  253,   484,    13,   449,     4,   253,   308,    10,    12, 19805,\n",
      "            28,     2,   901,     4,   187,    45,   120,    14,    17,   157,\n",
      "         13891,  1438, 23670,     4,   649,   829,  6620,  3033,   775,    13,\n",
      "          1438,    13, 13134,    60,     8,    64,    13,     4,    30, 26640,\n",
      "           308,     3,    13,   501,   455, 23539,   364,    76,   253,   253,\n",
      "            13,   818,   114,   253,  8809,    34,   265,  1690,     9,    13,\n",
      "             8, 17023,     5,     9],\n",
      "        [    6,   154,  2217,    27,     4,     6,    52, 16485,    18,     2,\n",
      "           622,   136,    26,     4,   777,  3212,   267,  1027,     8,  1276,\n",
      "            71,     2, 27320,     4,   184,  1567,  4865,   100,     8,   698,\n",
      "             2,  3030, 10839,     7,  3996,    11, 23148,     4,  1391, 16310,\n",
      "          1760,  1336,   698,  1860,     4,     2,     2,   663,     6,     6,\n",
      "          3030,    43,     5,     6,    48,   891,    30,   416,  1043,   598,\n",
      "           899,     2,     2, 17004],\n",
      "        [  554,     5,  4687,   200,     2,   554,    17,   829,    65, 23225,\n",
      "            15,     2, 19668,     4,   380,    43, 24432,    14,   959,   137,\n",
      "         16526,  1607,  1863,    86,     4,     2,     5,   204,     3,    79,\n",
      "          3790, 21970,  3828,   481, 21932,   241,   433,     4,     4, 19561,\n",
      "           196,  2067,    79, 16342,    13, 16080,  2085,   674,   554,   554,\n",
      "         19113,    13, 16791,   554,   197,   216,  8130,   111,  2349,  4170,\n",
      "           117,   829, 26790, 21456],\n",
      "        [20730,  1595, 18074,   304,  5094, 18695, 20633,     5,  6485, 16642,\n",
      "         19252,    79, 20254,     4, 17114, 16596, 21692,  1696,     5, 16733,\n",
      "             4, 17527, 18915, 22491, 16242, 27887,  7165,    14,  4270, 18101,\n",
      "         18606, 17542, 22278,    21, 21978,    24,     5,     4, 10289, 21061,\n",
      "         19367,  5291, 21897, 21399, 21785, 18430,  1815,     5, 21017, 20893,\n",
      "         21741, 17930, 21746, 16763,   644, 17826,  2086,     5, 18883, 16895,\n",
      "         20881,     1,     1,     1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch)\n",
    "text,label=batch.text,batch.target\n",
    "print(len(text))\n",
    "print(text[1])\n",
    "print(text[0])   \n",
    "# 搞不明白元组text第2个元素是什么？？？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSdhEVAd3EWE"
   },
   "source": [
    "**注意：测试集的数据顺序不需要改变，比赛中得到的结果需要提交**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPfRHqBgMkyZ"
   },
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FAvsdyFPaCIK"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1583386348513,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "ccsfTUpxYO6-",
    "outputId": "eebcabe1-6861-4eba-b9b9-b7b0bf67a736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:torch.Size([29257, 200])\n",
      "type:<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors # torch.Tensor [29257,200]\n",
    "info(pretrained_embeddings)\n",
    "\n",
    "model=TextCNN(embedding_dim,out_channels,kernel_size_list,output_dim,\n",
    "               dropout,pretrained_embeddings)\n",
    "optimizer = optim.Adam(model.parameters())  \n",
    "criterion = nn.CrossEntropyLoss()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "S3rzeXa-0plx"
   },
   "outputs": [],
   "source": [
    "def classifiction_metric(preds, labels, label_list):\n",
    "    \"\"\" 分类任务的评价指标， 传入的数据需要是 numpy 类型的 \"\"\"\n",
    "\n",
    "    acc = metrics.accuracy_score(labels, preds)\n",
    "\n",
    "    labels_list = [i for i in range(len(label_list))]\n",
    "\n",
    "    report = metrics.classification_report(\n",
    "        labels, preds, labels=labels_list, target_names=label_list, digits=5, output_dict=True)\n",
    "\n",
    "    return acc, report\n",
    "def evaluate(model, iterator, criterion, label_list):\n",
    "    model.eval()  \n",
    "    epoch_loss = 0\n",
    "    all_preds = np.array([], dtype=int)\n",
    "    all_labels = np.array([], dtype=int)\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "          # 模型进行推测时，要关闭梯度更新\n",
    "            with torch.no_grad():\n",
    "              logits = model(batch.text)\n",
    "\n",
    "            loss = criterion(logits.view(-1, len(label_list)), batch.target)\n",
    "\n",
    "            labels = batch.target.detach().cpu().numpy()\n",
    "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "            all_preds = np.append(all_preds, preds)\n",
    "            all_labels = np.append(all_labels, labels)\n",
    "            epoch_loss += loss.item()\n",
    "    acc, report = classifiction_metric(\n",
    "        all_preds, all_labels, label_list)\n",
    "\n",
    "    return epoch_loss/len(iterator), acc, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yP7UCFpJVb3t"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kjjr9FCokZAi"
   },
   "outputs": [],
   "source": [
    "train_dataloader=train_iter\n",
    "dev_dataloader=dev_iter \n",
    "label_list=['0', '1']  # 标签类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6904,
     "status": "ok",
     "timestamp": 1583386482207,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "qP6RiYFMgj4f",
    "outputId": "43d9925d-de0a-4d22-d12a-9375f3b95dc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/108 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch: 01 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|          | 1/108 [00:00<00:52,  2.06it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 10/108 [00:00<00:33,  2.89it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 20/108 [00:00<00:21,  4.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n",
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|██▊       | 30/108 [00:01<00:15,  5.20it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 41/108 [00:01<00:09,  7.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|████▋     | 50/108 [00:02<00:06,  8.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|█████▌    | 60/108 [00:02<00:04,  9.81it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 70/108 [00:02<00:02, 13.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|███████▍  | 80/108 [00:03<00:01, 18.02it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 90/108 [00:03<00:00, 23.84it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 100/108 [00:03<00:00, 28.37it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 108/108 [00:03<00:00, 31.62it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/108 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 9/108 [00:00<00:01, 85.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n",
      "---------------- Epoch: 02 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▊        | 20/108 [00:00<00:00, 91.03it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 32/108 [00:00<00:00, 89.74it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 42/108 [00:00<00:00, 85.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|████▊     | 52/108 [00:01<00:01, 35.37it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 64/108 [00:01<00:00, 44.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  71%|███████▏  | 77/108 [00:01<00:00, 55.46it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 86/108 [00:01<00:00, 34.35it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 97/108 [00:01<00:00, 43.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  98%|█████████▊| 106/108 [00:02<00:00, 50.86it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 108/108 [00:02<00:00, 52.12it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "writer = SummaryWriter(\n",
    "        log_dir=log_dir + '/' + time.strftime('%H:%M:%S', time.gmtime()))\n",
    "global_step = 0\n",
    "best_dev_loss = float('inf') # 最佳验证损失\n",
    "for epoch in range(epoch_num):\n",
    "# f-string: formatted string literals, 格式化字符串常量等同于str.format() \n",
    "  print(f'---------------- Epoch: {epoch+1:02} ----------')\n",
    "  epoch_loss = 0\n",
    "  train_steps = 0\n",
    "\n",
    "  all_preds = np.array([], dtype=int)\n",
    "  all_labels = np.array([], dtype=int)\n",
    "  for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "    optimizer.zero_grad()\n",
    "    logits=model(batch.text) \n",
    "    # 注意这里将标签进行调增为(batch_num,class_num)的形式，才方便调用函数计算\n",
    "    loss = criterion(logits.view(-1, len(label_list)), batch.target) # 计算loss值\n",
    "\n",
    "    # 得到实际的标签与预测的标签存储起来\n",
    "    labels = batch.target.detach().cpu().numpy()\n",
    "    preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "    # 进行参数优化\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    global_step += 1\n",
    "    # \n",
    "    epoch_loss += loss.item() #得到具体数值\n",
    "    train_steps += 1\n",
    "\n",
    "    all_preds = np.append(all_preds, preds)\n",
    "    all_labels = np.append(all_labels, labels)\n",
    "\n",
    "    if global_step % print_step == 0:\n",
    "      # 计算当前loss值，准确率，召回率\n",
    "      train_loss = epoch_loss / train_steps\n",
    "      train_acc, train_report = classifiction_metric(\n",
    "                    all_preds, all_labels, label_list)\n",
    "      \n",
    "      # 使用验证集验证模型\n",
    "      dev_loss, dev_acc, dev_report = evaluate(\n",
    "                    model, dev_dataloader, criterion, label_list)\n",
    "\n",
    "\n",
    "\n",
    "      # 将画图用到的数据添加到画图类中\n",
    "      c = global_step // print_step\n",
    "\n",
    "      writer.add_scalar(\"loss/train\", train_loss, c)\n",
    "      writer.add_scalar(\"loss/dev\", dev_loss, c)\n",
    "\n",
    "      writer.add_scalar(\"acc/train\", train_acc, c)\n",
    "      writer.add_scalar(\"acc/dev\", dev_acc, c)\n",
    "\n",
    "      # 这里是label list\n",
    "      for label in label_list:\n",
    "        writer.add_scalar(label + \":\" + \"f1/train\",\n",
    "                    train_report[label]['f1-score'], c)\n",
    "        writer.add_scalar(label + \":\" + \"f1/dev\",\n",
    "                    dev_report[label]['f1-score'], c)\n",
    "        \n",
    "      # 注意这里是print_list\n",
    "      print_list = ['macro avg', 'weighted avg']\n",
    "      for label in print_list:\n",
    "        writer.add_scalar(label + \":\" + \"f1/train\",train_report[label]['f1-score'], c)\n",
    "        writer.add_scalar(label + \":\" + \"f1/dev\",dev_report[label]['f1-score'], c)\n",
    "\n",
    "      if dev_loss < best_dev_loss:\n",
    "        best_dev_loss = dev_loss\n",
    "        torch.save(model.state_dict(),model_file)\n",
    "        print(\"new model saved\")\n",
    "      model.train()\n",
    "writer.close()\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMuLjf3yTkXB"
   },
   "source": [
    "#### 使用模型进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WRVXCh-SYh8q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21w7uD3NYiKg"
   },
   "source": [
    "[pytorch中detach的用法](https://www.cnblogs.com/jiangkejie/p/9981707.html)\n",
    "\n",
    "[变量类型(cpu/gpu)](https://blog.csdn.net/g11d111/article/details/80896137)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1583386488917,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "dyGhPMjRTjI2",
    "outputId": "01a077d2-4ad5-4ac2-9864-e5d522318cc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/51 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 51/51 [00:00<00:00, 524.37it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "test_preds = np.array([], dtype=int)\n",
    "# 加载模型参数，这里的model必须提前定义好\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "for batch in tqdm(test_iter):\n",
    "  with torch.no_grad(): # 模型推测是关闭梯度更新\n",
    "    logits = model(batch.text)\n",
    "  preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "  # 将计算结果从计算图中分开，并转换为cpu变量，再转换为numpy数组\n",
    "  test_preds = np.append(test_preds, preds)\n",
    "\n",
    "# detach(分开，脱离)：Returns a new Tensor, detached from the current graph.\n",
    "# The result will never require gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1632,
     "status": "ok",
     "timestamp": 1583387125471,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "YmFfIw1bpQ35",
    "outputId": "2ed17157-e558-406e-e053-2cdaf67e4f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3263,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_preds.shape)   # 测试数据为3263\n",
    "print(type(all_preds))\n",
    "path2 = root_dir+'test.csv'\n",
    "test_data = pd.read_csv(path2)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1639,
     "status": "ok",
     "timestamp": 1583387225976,
     "user": {
      "displayName": "stellar young",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64",
      "userId": "04365853722201802512"
     },
     "user_tz": -480
    },
    "id": "vP9IaOy1MJo0",
    "outputId": "805e84b2-23fc-4627-92b7-9b2303dae04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  target\n",
      "0   0       1\n",
      "1   2       1\n",
      "2   3       0\n",
      "3   9       0\n",
      "4  11       1\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame(data={'id':test_data.id,'target':test_preds})\n",
    "print(submission_df.head())\n",
    "submission_df.to_csv('res.csv', sep=\",\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZooZnsyZuWf"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyONMI+tRX8GS3icxf0d6WLG",
   "collapsed_sections": [],
   "mount_file_id": "1Es12alVriOfMEAxXfHt2eILf0J5EpO_M",
   "name": "01_kaggle_text_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
