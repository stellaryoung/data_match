{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"“02 HAN_dgl_acm.ipynb”的副本","provenance":[{"file_id":"1YYqUd7UlQGjLOCLcbeCi8vVuRos46w2J","timestamp":1584349335024}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MG3jMnGX64N0","colab_type":"text"},"source":["### HAN网络代码理解(使用DGL)"]},{"cell_type":"code","metadata":{"id":"obQrL8GUuAUq","colab_type":"code","outputId":"cf3b9888-43b1-4405-a5a3-9af8dc9bbf5b","executionInfo":{"status":"ok","timestamp":1584346576282,"user_tz":-480,"elapsed":4159,"user":{"displayName":"stellar young","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64","userId":"04365853722201802512"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["!pip install dgl-cu101 # install deep graph library"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: dgl-cu101 in /usr/local/lib/python3.6/dist-packages (0.4.2)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (2.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.17.5)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl-cu101) (4.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0s38bvv47oJ-","colab_type":"code","colab":{}},"source":["import torch\n","import dgl\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dgl.nn.pytorch import GATConv   # call dgl library\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"erJficWewfmQ","colab_type":"text"},"source":["###**Question**:Does GAT layer is the same as part of node-level attention of HAN?\n","***\n","**------------------node-level attention in HAN-------------------**\n","\n","**01 Type specific transformation of node feature**:\n","\n","$\\mathbf{h}_{i}^{\\prime}=\\mathbf{M}_{\\phi_{i}} \\cdot \\mathbf{h}_{i}$\n","\n","**02 weight coefficient of node:**\n","\n","$\\alpha_{i j}^{\\Phi}=\\operatorname{softmax}_{j}\\left(e_{i j}^{\\Phi}\\right)=\\frac{\\exp \\left(\\sigma\\left(\\mathbf{a}_{\\Phi}^{\\mathrm{T}} \\cdot\\left[\\mathbf{h}_{i}^{\\prime} \\| \\mathbf{h}_{j}^{\\prime}\\right]\\right)\\right)}{\\sum_{k \\in \\mathcal{N}_{i}^{\\oplus}} \\exp \\left(\\sigma\\left(\\mathbf{a}_{\\Phi}^{\\mathrm{T}} \\cdot\\left[\\mathbf{h}_{i}^{\\prime} \\| \\mathbf{h}_{k}^{\\prime}\\right]\\right)\\right)}$\n","\n","**03 the meta-path based embedding of node**\n","\n","$\\mathbf{z}_{i}^{\\Phi}=\\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}^{\\phi}} \\alpha_{i j}^{\\Phi} \\cdot \\mathbf{h}_{j}^{\\prime}\\right)$\n","\n","**04 concatenate the learned embeddings as the semantic-specific embedding**\n","\n","$\\mathbf{z}_{i}^{\\Phi}=\\prod_{k=1}^{K} \\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}^{\\phi}} \\alpha_{i j}^{\\Phi} \\cdot \\mathbf{h}_{j}^{\\prime}\\right)$\n","***\n","**总结:异质图通过元路径转化为多张图，假设异质图中定义了3种元路径，则产生3张图，对于3张图，每个图的特征提取过程都如上所示，使用了self-attention,masked-attention,multi-head attention。**\n","***\n","注意：从GAT论文与HAN论文的描述来看，以上四个步骤与GAT论文中node-level attention的描述是一致的，**区别在于HAN的将其应用到通过元路径产生的多张图，作为node-level attention，这就解释了dgl库中直接将GATConv进行封装**。\n"]},{"cell_type":"markdown","metadata":{"id":"6L4cXm9Yro95","colab_type":"text"},"source":["### semantic-level attention\n","***\n","**importance of each meta-path**:\n","$w_{\\Phi_{i}}=\\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\mathbf{q}^{\\mathrm{T}} \\cdot \\tanh \\left(\\mathbf{W} \\cdot \\mathbf{z}_{i}^{\\Phi}+\\mathbf{b}\\right)$\n","\n","$W$ is the weight matrix, $b$ is the bias vector, $q$ is the semantic- level attention vector\n","***\n","\n"]},{"cell_type":"code","metadata":{"id":"2AnQ0bEqARPy","colab_type":"code","colab":{}},"source":["# learn the importance of each meta-path and assign proper weights to them\n","# z:(node_num,num_meta_paths,in_size)\n","class SemanticAttention(nn.Module):\n","    def __init__(self, in_size, hidden_size=128):\n","        super(SemanticAttention, self).__init__()\n","\n","        self.project = nn.Sequential(\n","            nn.Linear(in_size, hidden_size), # (node_num,num_meta_paths,hidden_size)\n","            nn.Tanh(),\n","            nn.Linear(hidden_size, 1, bias=False) #(node_num,num_meta_paths,1) \n","            # here, use linear transformation as dot q and average\n","        )\n","# (node_num,num_meta_paths,1)*(node_num,num_meta_paths,in_size)==(node_num,num_meta_paths,in_size)\n","    def forward(self, z):\n","        w = self.project(z) # w:(node_num,num_meta_paths,1)\n","        print(w.shape)\n","        beta = torch.softmax(w, dim=1) # beta:(node_num,num_meta_paths,1)\n","        # beta*z:(node_num,num_meta_paths,in_size),this is element-wise product(with broadcast)\n","        return (beta * z).sum(1)  # 这里tensor相乘用到了广播机制，最终效果就是实现加权求和"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmLxdQdVYIzk","colab_type":"code","outputId":"70a9fa1e-95fd-4dc4-d92a-67f80bab7c66","executionInfo":{"status":"ok","timestamp":1584347126615,"user_tz":-480,"elapsed":1055,"user":{"displayName":"stellar young","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64","userId":"04365853722201802512"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["test_z = torch.randn(100,3,256)\n","test_layer = SemanticAttention(256,128)\n","out = test_layer(test_z)\n","print(out.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["torch.Size([100, 3, 1])\n","torch.Size([100, 256])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XkcE87tT5-A1","colab_type":"text"},"source":["### HANLayer\n","异质图中定义了多少元路径，就需要多少GAT_layer并行处理图来node-level attention。\n","\n","dgl中GATConv比还有其他参数，可以看官方手册。"]},{"cell_type":"code","metadata":{"id":"6hAFyG-YvjVK","colab_type":"code","colab":{}},"source":["class HANLayer(nn.Module):\n","  def __init__(self,num_meta_paths,in_size,out_size,num_heads,dropout):\n","    super(HANLayer,self).__init__()\n","    self.gat_layers=nn.ModuleList()\n","    # node-level attention\n","    for tmp in range(num_meta_paths):\n","      self.gat_layers.append(GATConv(in_size,out_size,num_heads,\n","                    dropout,dropout,activation=F.elu))\n","    # semantic-level attention\n","    self.semantic_attention = SemanticAttention(num_heads*out_size)\n","    self.num_meta_paths = num_meta_paths\n","  def forward(self,graph_list,node_feature):\n","    semantic_embeddings=[]\n","    for i,graph in enumerate(graph_list): \n","      # 这里由于利用了dgl官方的函数,所以必须进行使用官方的图类型graph\n","      semantic_embeddings.append(self.gat_layers[i](graph,node_feature).flatten(1))\n","    # [N,H,D_out]--------flatten------->[N,H*D_out]\n","    semantic_embedding=torch.stack(semantic_embeddings,dim=1)\n","    # [N,num_meat_paths,H*D_out]\n","    return self.semantic_attention(semantic_embedding) # [N,H*D_out]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I-R3KF8vdRD-","colab_type":"code","colab":{}},"source":["from scipy.sparse import coo_matrix\n","import networkx as nx"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oKsjSHxCSHk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"outputId":"1bba58ce-57ce-457c-8501-49b8d376fcd9","executionInfo":{"status":"error","timestamp":1584348082168,"user_tz":-480,"elapsed":982,"user":{"displayName":"stellar young","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64","userId":"04365853722201802512"}}},"source":["# coo_matrix:(row,column,value)\n","# -----------------way to creat graph-----------------------------\n","spmat = coo_matrix(([1,1,1], ([0, 0, 1], [2, 3, 2])), shape=(10, 10))\n","# print(spmat.todense()) # todense()可以看到所创建的矩阵\n","test_graph1 = dgl.graph(spmat)\n","test_graph2 = dgl.graph(spmat)\n","features=torch.randn(10,100)\n","in_size=100\n","out_size=8\n","num_heads=8\n","dropout=0.6\n","test_model_1 = GATConv(in_size,out_size,num_heads,dropout,dropout,activation=F.elu)\n","out = test_model_1(test_graph1,features)"],"execution_count":28,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-d36d68fb430d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_model_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGATConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_graph1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/conv/gatconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# compute softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;31m# message passing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/softmax.py\u001b[0m in \u001b[0;36medge_softmax\u001b[0;34m(graph, logits, eids)\u001b[0m\n\u001b[1;32m    177\u001b[0m         [0.5000]])\n\u001b[1;32m    178\u001b[0m     \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mEdgeSoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/softmax.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, g, score, eids)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mn_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mn_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mgidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_immutable_gidx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dgl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgidx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/_ffi/_ctypes/object.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret_success\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             raise AttributeError(\n\u001b[0;32m---> 61\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (str(type(self)), name))\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRETURN_SWITCH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mret_type_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: '<class 'dgl.heterograph_index.HeteroGraphIndex'>' object has no attribute 'get_immutable_gidx'"]}]},{"cell_type":"code","metadata":{"id":"H8x4iGpCg1IS","colab_type":"code","colab":{}},"source":["# 这里其实将看是否需要叠加多层HAN\n","class HAN(nn.Module):\n","  # out_size: number of node class \n","  def __init__(self,num_meta_paths,in_size,hidden_size,out_size,num_head_list,dropout):\n","    super(HAN,self).__init__()\n","    self.layers = nn.ModuleList()\n","    self.layers.append(HANLayer(num_meta_paths,in_size,hidden_size,num_head_list[0],dropout))\n","    # 第一层的原始特征要单独拿出来\n","    for i in range(1,len(num_head_list)):\n","      self.layers.append(HANLayer(num_meta_paths,hidden_size*num_head_list[i],\n","                    hidden_size,num_head_list[i],dropout))\n","    self.predict = nn.Linear(hidden_size*num_head_list[-1],out_size) # x线性变换用于分类 \n","  def forward(self,graph_list,h):\n","    for layer in self.layers:\n","      h = layer(graph_list,h)\n","    return self.predict(h)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_80ZpCHxJkda","colab_type":"text"},"source":["### 加载ACM数据集(dgl版本)"]},{"cell_type":"code","metadata":{"id":"Iav82suG8-jC","colab_type":"code","colab":{}},"source":["import pickle\n","import dgl\n","from scipy import sparse # 这个常用于存储矩阵\n","from scipy import io as sio"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UqMz6ynH5KTW","colab_type":"code","outputId":"e7cafa37-4bcd-4a5c-8645-5775166f7b91","executionInfo":{"status":"ok","timestamp":1584187025974,"user_tz":-480,"elapsed":2813,"user":{"displayName":"stellar young","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64","userId":"04365853722201802512"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# 下载dgl提供的HAN的ACM数据集\n","# dgl ACM dataset:https://data.dgl.ai/dataset/ACM3025.pkl\n","import urllib\n","data_path = '/content/drive/My Drive/GNN/data/ACM_HAN/'\n","url = 'https://data.dgl.ai/dataset/ACM3025.pkl'\n","urllib.request.urlretrieve(url, data_path+\"ACM3025.pkl\")\n","print(\"finish downloading\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["finish downloading\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O-COAhb8JRa5","colab_type":"code","colab":{}},"source":["# 这里的self-loop是指每个结点与自己本身是否有边相连\n","# 该数据加载中调用了dgl libray用于建立使用元路径定义的同质图\n","\n","def get_binary_mask(total_size, indices):\n","    mask = torch.zeros(total_size)\n","    mask[indices] = 1\n","    return mask.byte() # convert to torch.uint8\n","\n","def load_acm(remove_self_loop,data_path):\n","    with open(data_path, 'rb') as f:\n","        data = pickle.load(f)  # type(data): class dict\n","    # type(data['label']): <class 'scipy.sparse.csr.csr_matrix'>\n","    # crs: Compressed Sparse Row matrix\n","    # todense(): Return a dense matrix representation of this matrix.\n","    # todense():将采用特殊格式存储的数据转化为numpy数组即（dense matrix）\n","    # 获取结点标签以及特征\n","    labels, features = torch.from_numpy(data['label'].todense()).long(), \\\n","                       torch.from_numpy(data['feature'].todense()).float()\n","    # print(labels.shape)       # torch.Size([3025, 3])\n","    # print(features.shape)      # torch.Size([3025, 1870])\n","    num_classes = labels.shape[1] # 论文三分类(Database, Wireless Communication, Data Mining)\n","    # print(labels[0,:])        # tensor([1, 0, 0]),标签采用的one-hot编码\n","    # print(labels.nonzero().shape)  # torch.Size([3025, 2]),每行存储的是非0元素的索引\n","    labels = labels.nonzero()[:, 1] # 本质上这句将one-hot变成用0，1，2表示标签\n","    \n","    if remove_self_loop:\n","        num_nodes = data['label'].shape[0]\n","        data['PAP'] = sparse.csr_matrix(data['PAP'] - np.eye(num_nodes))\n","        data['PLP'] = sparse.csr_matrix(data['PLP'] - np.eye(num_nodes))\n","\n","    # Adjacency matrices for meta path based neighbors\n","    # (Mufei): I verified both of them are binary adjacency matrices with self loops\n","    # 这里直接建立了使用元路径从异质图转化来的2个同质图\n","    # 这里PLP就是原论文中PSP\n","    # ntype是结点名称，etype是边的名称\n","    author_g = dgl.graph(data['PAP'], ntype='paper', etype='author')\n","    subject_g = dgl.graph(data['PLP'], ntype='paper', etype='subject')\n","\n","    gs = [author_g, subject_g]\n","\n","    train_idx = torch.from_numpy(data['train_idx']).long().squeeze(0)\n","    val_idx = torch.from_numpy(data['val_idx']).long().squeeze(0)\n","    test_idx = torch.from_numpy(data['test_idx']).long().squeeze(0)\n","\n","    num_nodes = author_g.number_of_nodes()\n","    train_mask = get_binary_mask(num_nodes, train_idx)\n","    val_mask = get_binary_mask(num_nodes, val_idx)\n","    test_mask = get_binary_mask(num_nodes, test_idx)\n","\n","    print('dataset loaded')\n","    # print({\n","    #     'dataset': 'ACM',\n","    #     'train': train_mask.sum().item() / num_nodes,\n","    #     'val': val_mask.sum().item() / num_nodes,\n","    #     'test': test_mask.sum().item() / num_nodes\n","    # })\n","\n","    return gs, features, labels, num_classes, train_idx, val_idx, test_idx, \\\n","           train_mask, val_mask, test_mask"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwH40eIP7Z5T","colab_type":"code","outputId":"22ba1c86-946d-49d8-d068-6fa3146dcd4e","executionInfo":{"status":"ok","timestamp":1584338603478,"user_tz":-480,"elapsed":1169,"user":{"displayName":"stellar young","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64","userId":"04365853722201802512"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["def get_device():\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    n_gpu = torch.cuda.device_count()\n","    if torch.cuda.is_available():\n","        print(\"device is cuda, # cuda is: \", n_gpu)\n","    else:\n","        print(\"device is cpu, not recommend\")\n","    return device, n_gpu\n","device, n_gpu = get_device()\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["device is cuda, # cuda is:  1\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lIphlCFW6vm1","colab_type":"code","colab":{}},"source":["# The configuration below is from the paper.\n","default_configure = {\n","    'lr': 0.005,          # Learning rate\n","    'num_heads': [8],        # Number of attention heads for node-level attention\n","    'hidden_units': 8,\n","    'dropout': 0.6,\n","    'weight_decay': 0.001,\n","    'num_epochs': 200,\n","    'patience': 100\n","}\n","\n","sampling_configure = {\n","    'batch_size': 20\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"soLDmIIR4rUj","colab_type":"text"},"source":["### 模型训练\n","\n","使用GPU进行训练图网络时，最好将模型与特征都送入到GPU中"]},{"cell_type":"code","metadata":{"id":"lTZH4wrN8HTc","colab_type":"code","outputId":"0ea21b1f-6c23-40b3-f804-d6ceb22b7d6d","executionInfo":{"status":"ok","timestamp":1584338543251,"user_tz":-480,"elapsed":2970,"user":{"displayName":"stellar young","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64","userId":"04365853722201802512"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# graph_list:列表中同质图的邻接矩阵,有self-loop,该图的类型是dgl库中特有的类型\n","# features: In ACM dataset, features of paper (node_num,dim)-->([3025, 1870])\n","# labels:  labels of nodes (node_num)-->([3025])\n","# num_classes: number of node class --> 3\n","# train_idx: ([600])   tensor\n","# val_idx:  ([300])   tensor\n","# test_idx： ([2125])   tensor\n","# 上面3行数目加起来正好是3025\n","# train_mask、val_mask、test_mask：torch.uint8,[3025]\n","# mask张量大小与节点总的数目一致\n","# print(type(graph_list[0])) # dgl.heterograph.DGLHeteroGraph\n","data_path = '/content/drive/My Drive/GNN/data/ACM_HAN/'\n","data_path = data_path+\"ACM3025.pkl\"\n","graph_list,features,labels,num_classes,train_idx,val_idx,test_idx, \\\n","train_mask,val_mask,test_mask=load_acm(remove_self_loop=False,data_path=data_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["dataset loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"40iCqmKG5A_h","colab_type":"code","colab":{}},"source":["# 将数据送入到GPU\n","features = features.to(device)\n","labels = labels.to(device)\n","train_mask = train_mask.to(device)\n","val_mask = val_mask.to(device)\n","test_mask = test_mask.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckcSWG5V8cZw","colab_type":"code","outputId":"ed33f731-9904-482b-aacf-38ce5b57dea7","executionInfo":{"status":"error","timestamp":1584339950218,"user_tz":-480,"elapsed":1221,"user":{"displayName":"stellar young","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgglPFChr_yKiw2MFtjKsjqzJ2VTKrvbyjEF83J=s64","userId":"04365853722201802512"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["# model = HAN(num_meta_paths=len(g),in_size=features.shape[1],hidden_size=args['hidden_units'],\n","#         out_size=num_classes,num_heads=args['num_heads'],dropout=args['dropout']).to(device)\n","model=HAN(num_meta_paths=len(graph_list),\n","       in_size=features.shape[1],\n","       hidden_size=8,\n","       out_size=num_classes,\n","       num_head_list=[8],\n","       dropout=0.6)\n","model.to(device)\n","output = model(graph_list,features)\n","print(output.shape)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-86fcf61516e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m        dropout=0.6)\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-22e66ee90b0f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph_list, h)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-f192a5076f45>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph_list, node_feature)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m# 这里由于利用了dgl官方的函数,所以必须进行使用官方的图类型graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0msemantic_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# [N,H,D_out]--------flatten------->[N,H*D_out]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msemantic_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemantic_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/conv/gatconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# compute softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;31m# message passing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/softmax.py\u001b[0m in \u001b[0;36medge_softmax\u001b[0;34m(graph, logits, eids)\u001b[0m\n\u001b[1;32m    177\u001b[0m         [0.5000]])\n\u001b[1;32m    178\u001b[0m     \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mEdgeSoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/softmax.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, g, score, eids)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mn_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mn_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mgidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_immutable_gidx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dgl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgidx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/_ffi/_ctypes/object.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret_success\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             raise AttributeError(\n\u001b[0;32m---> 61\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (str(type(self)), name))\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRETURN_SWITCH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mret_type_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: '<class 'dgl.heterograph_index.HeteroGraphIndex'>' object has no attribute 'get_immutable_gidx'"]}]}]}