{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参考链接：\n",
    "* [pytorch官方教程](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pytorch是什么？**\n",
    "* 取代numpy，专门用于GPU计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor的创建\n",
    "* torch.empty(5, 3):没有初始化的矩阵\n",
    "* torch.rand(5,3):随机初始化\n",
    "* torch.zeros(7, 3, dtype=torch.long):初始化为0，并指定数据类型为long\n",
    "* torch.tensor([23.23, 0.23,29823998,32023])：将已有数据转变为tensor,列表中存有数据\n",
    "* x = x.new_ones(2, 2, dtype=torch.double):将已有的tensor变为新的tensor，并指定类型\n",
    "* x = torch.randn_like(x, dtype=torch.float):改变已有tensor变量类型并将其创建为新的tensor\n",
    "\n",
    "### tensor的常用操作\n",
    "* x.size() :返回一个tuple，用于反映tensor维度，该tuple支持一切元组操作\n",
    "* tensor加法的语法（x,y为同等大小tensor）：\n",
    "    * print(x + y)\n",
    "    * print(torch.add(x, y))\n",
    "    * result = torch.empty(5, 3),torch.add(x, y, out=result)  ：将运算结果存在定义的result张量中\n",
    "    * y.add_(x)   ：带有后缀_会改变参与运算的张量的值，这里原有y信息丢失\n",
    "* print(x[:, 2])   ：取tensor的第三列，操作方法与numpy索引一致\n",
    "* z = x.view(-1, 8) ：改变tensor的维度，the size -1 is inferred from other dimensions\n",
    "* x.item()       ：one element tensor，get the value as a Python number.\n",
    "\n",
    "\n",
    "### [更多tensor的操作](https://pytorch.org/docs/stable/torch.html)\n",
    "\n",
    "### tensor与numpy的转换\n",
    "**注意点：火炬张量和numpy数组(转换前后)将共享其底层内存位置（如果火炬张量在CPU上），更改一个将更改另一个。**\n",
    "numpy1 = tensor1.numpy() : tensor --> numpy\n",
    "tensor2 = torch.from_numpy(numpy2):numpy -->tensor\n",
    "\n",
    "### CUDA Tensors\n",
    "Tensors can be moved onto any device using the .to method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor的创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tensor与numpy中的多维数组ndarrays相似，但是**tensor可以在GPU中加速运算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.7245e-39, 9.2755e-39, 8.9082e-39],\n",
      "        [9.9184e-39, 8.4490e-39, 9.6429e-39],\n",
      "        [1.0653e-38, 1.0469e-38, 4.2246e-39],\n",
      "        [1.0378e-38, 9.6429e-39, 9.2755e-39],\n",
      "        [1.0928e-38, 9.9184e-39, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# 1 declare an uninitialized matrix,\n",
    "# 2 don't contain definite known values before it is used.\n",
    "# 3 whatever values were in the allocaoted at the time will appear as the initial values(如果不专门初始化，分配的内存中的值将会作为初始值)\n",
    "x = torch.empty(5, 3)   # 声明一个未初始化矩阵\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5389, 0.3563, 0.7202],\n",
      "        [0.0048, 0.7399, 0.5728],\n",
      "        [0.8696, 0.7727, 0.7794],\n",
      "        [0.9452, 0.6700, 0.4919],\n",
      "        [0.6068, 0.6264, 0.9549]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)   # construct a randomly initialized martrix(声明矩阵，并随机初始化)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(7, 3, dtype=torch.long)  # construct a matrix filled zeros and of dtyoe long\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3230e+01, 2.3000e-01, 2.9824e+07, 3.2023e+04])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.2478, -0.6487],\n",
      "        [-0.6725,  0.6654]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([23.23, 0.23,29823998,32023]) # construct a tensor directly from data\n",
    "print(x)\n",
    "\n",
    "x = x.new_ones(2, 2, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-2.1434,  0.4270, -1.8853],\n",
      "        [ 0.7491,  1.0260,  1.1579],\n",
      "        [ 2.1681, -0.9536,  1.3202],\n",
      "        [ 0.0486,  1.8332, -0.8583],\n",
      "        [-0.8186,  0.1031,  1.1943]], dtype=torch.float64)\n",
      "tensor([[ 0.0566, -0.2815, -1.3402],\n",
      "        [ 0.0433, -1.7631,  1.4269],\n",
      "        [ 1.2746, -0.8874,  1.4833],\n",
      "        [-0.9965,  1.8236, -0.3645],\n",
      "        [ 2.0717, -1.2871, -0.3986]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "x = torch.randn_like(x)                       # 继承了之前tensor的类型\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor的常用操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(x.size())     # torch.size in fact a tuple,so it supports all tuple operations\n",
    "d = x.size()[1]     \n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0566, -0.2815, -1.3402],\n",
      "        [ 0.0433, -1.7631,  1.4269],\n",
      "        [ 1.2746, -0.8874,  1.4833],\n",
      "        [-0.9965,  1.8236, -0.3645],\n",
      "        [ 2.0717, -1.2871, -0.3986]])\n",
      "tensor([[0.9763, 0.4136, 0.5451],\n",
      "        [0.9530, 0.6346, 0.2831],\n",
      "        [0.3156, 0.0083, 0.3041],\n",
      "        [0.8070, 0.2229, 0.6649],\n",
      "        [0.4117, 0.2119, 0.5572]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "y = torch.rand(5,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0328,  0.1321, -0.7950],\n",
      "        [ 0.9963, -1.1285,  1.7100],\n",
      "        [ 1.5902, -0.8792,  1.7874],\n",
      "        [-0.1895,  2.0464,  0.3004],\n",
      "        [ 2.4835, -1.0752,  0.1586]])\n",
      "tensor([[ 1.0328,  0.1321, -0.7950],\n",
      "        [ 0.9963, -1.1285,  1.7100],\n",
      "        [ 1.5902, -0.8792,  1.7874],\n",
      "        [-0.1895,  2.0464,  0.3004],\n",
      "        [ 2.4835, -1.0752,  0.1586]])\n",
      "tensor([[ 1.0328,  0.1321, -0.7950],\n",
      "        [ 0.9963, -1.1285,  1.7100],\n",
      "        [ 1.5902, -0.8792,  1.7874],\n",
      "        [-0.1895,  2.0464,  0.3004],\n",
      "        [ 2.4835, -1.0752,  0.1586]])\n",
      "tensor([[ 1.0328,  0.1321, -0.7950],\n",
      "        [ 0.9963, -1.1285,  1.7100],\n",
      "        [ 1.5902, -0.8792,  1.7874],\n",
      "        [-0.1895,  2.0464,  0.3004],\n",
      "        [ 2.4835, -1.0752,  0.1586]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "t = x+y\n",
    "print(t)\n",
    "\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0328,  0.1321, -0.7950],\n",
      "        [ 0.9963, -1.1285,  1.7100],\n",
      "        [ 1.5902, -0.8792,  1.7874],\n",
      "        [-0.1895,  2.0464,  0.3004],\n",
      "        [ 2.4835, -1.0752,  0.1586]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)   # have post-fixed with an _,会改变本来的值，这里计算x+y,是将y存储运算结果，原有的y丢失\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0566, -0.2815, -1.3402],\n",
      "        [ 0.0433, -1.7631,  1.4269],\n",
      "        [ 1.2746, -0.8874,  1.4833],\n",
      "        [-0.9965,  1.8236, -0.3645],\n",
      "        [ 2.0717, -1.2871, -0.3986]])\n",
      "tensor([-1.3402,  1.4269,  1.4833, -0.3645, -0.3986])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x[:, 2])  # 取tensor的第三列，操作方法与numpy索引一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0357784032821655\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x.item())  # 将one item tensor 转换位value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor与numpy的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.ones(5)\n",
    "print(tensor1)\n",
    "numpy1 = tensor1.numpy()\n",
    "print(numpy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy2 = np.ones(5)\n",
    "tensor2 = torch.from_numpy(numpy2)\n",
    "np.add(numpy2, 1, out=numpy2)\n",
    "print(numpy2)\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0358], device='cuda:0')\n",
      "tensor([2.0358], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
